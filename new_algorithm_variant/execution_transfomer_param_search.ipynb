{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader as PygDataLoader\n",
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch_geometric.data import DataLoader\n",
    "from dataloader import NCaltech101Best\n",
    "from model import GraphRes, GraphResModified, GraphResSimple, GraphTrans\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "batch_size= 16\n",
    "lr=         10e-3 # decreases by 10 after each 20 epochs\n",
    "loss=       th.nn.CrossEntropyLoss\n",
    "batchsize=  16\n",
    "K=          10 # data subsampling\n",
    "nclasses=   100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_LAUNCH_BLOCKING=1\n"
     ]
    }
   ],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cpu\n"
     ]
    }
   ],
   "source": [
    "# Set device to use for training\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print(\"using device:\", device)\n",
    "\n",
    "def single_run(batch_size, num_samples, trans_heads, dropout_trans, epochs):\n",
    "    # Initialize dataset\n",
    "    dataset = NCaltech101Best('./data/storage/', mode='train', num_samples=num_samples)\n",
    "\n",
    "    # training data\n",
    "    loader = PygDataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    print(\"example datapoint:\", dataset.get(0))\n",
    "    \n",
    "    # testing data and function\n",
    "    test_dataset = NCaltech101Best('./data/storage/', mode='test')\n",
    "    test_loader = PygDataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "    def run_model_test(model, loader):\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        for data in tqdm(loader):\n",
    "            data = data.to(device)\n",
    "            with torch.no_grad():\n",
    "                out = model(data)\n",
    "                pred = out.max(dim=1)[1]\n",
    "                correct += pred.eq(data.y).sum().item()\n",
    "        return correct / len(loader.dataset)\n",
    "\n",
    "    # Initialize model\n",
    "    model_input_shape = th.tensor((240, 180) + (3, ), device=device)\n",
    "    print(\"INPUT SHAPE:\", model_input_shape)\n",
    "    model = GraphTrans('ncaltech101', model_input_shape, 101, dropout_trans=dropout_trans, heads=trans_heads).to(device)\n",
    "\n",
    "    # Define loss function and optimizer\n",
    "    criterion = CrossEntropyLoss().to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "    acc = []\n",
    "    test_acc = []\n",
    "    # Define training loop\n",
    "    def train():\n",
    "        model.train()\n",
    "        losses = []\n",
    "        correct = 0\n",
    "        i = 0\n",
    "        print(\"234 iterations in total:\")\n",
    "        progbar = tqdm(loader)\n",
    "        for data in progbar:\n",
    "\n",
    "            # inference\n",
    "            data = data.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "\n",
    "            # weight updates\n",
    "            y = F.one_hot(data.y, num_classes=101).type(torch.float32)\n",
    "            loss = criterion(output, y)\n",
    "            losses.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # precision logging\n",
    "            pred = output.max(dim=1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "            i += 1\n",
    "            # if i % 50 == 0:\n",
    "            #     print(correct, i*16)\n",
    "            #     print(correct / (i*16))\n",
    "            # if i % 20 == 0 and i != 0:\n",
    "            #     print((i, round(correct / (i*16), 2)), end='->')\n",
    "            # if i % 100 == 0 and i != 0:   \n",
    "            #     print(\"\\n\", end='')\n",
    "            precision = round(correct / (i*batch_size), 2)\n",
    "            progbar.set_description(\"precision so far is {}\".format(precision))\n",
    "            data = data.to('cpu')\n",
    "        \n",
    "        # test, to check for overfitting\n",
    "        tacc = run_model_test(model, test_loader)\n",
    "        test_acc.append(tacc)\n",
    "        \n",
    "        acc.append(correct / (len(loader) * batch_size))\n",
    "        print(\"train accuracy: {}, test accuracy: {}\".format(acc[len(acc) - 1], tacc))\n",
    "        return losses\n",
    "\n",
    "    def clean_losses(losses):\n",
    "        clean = []\n",
    "        for loss in losses:\n",
    "            ll = [float(l.cpu().detach().numpy()) for l in loss]\n",
    "            clean.append(ll)\n",
    "        return clean\n",
    "\n",
    "    # Run training loop for n epochs\n",
    "    all_losses = []\n",
    "    for epoch in range(epochs):\n",
    "        print(\"computing epoch\", epoch)\n",
    "        losses = train()\n",
    "        all_losses.append(losses)\n",
    "        if epoch > 0 and test_acc[-1] < 0.1:\n",
    "            return max(test_acc), test_acc, clean_losses(all_losses)\n",
    "        if epoch > 10 and test_acc[-1] < test_acc[len(test_acc) - 6]:\n",
    "            return max(test_acc), test_acc, clean_losses(all_losses)\n",
    "    return max(test_acc), test_acc, clean_losses(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(16, 100, 3, False, 10), (16, 100, 3, False, 50), (16, 100, 3, True, 10), (16, 100, 3, True, 50), (16, 100, 1, False, 10), (16, 100, 1, False, 50), (16, 100, 1, True, 10), (16, 100, 1, True, 50), (16, 100, 5, False, 10), (16, 100, 5, False, 50), (16, 100, 5, True, 10), (16, 100, 5, True, 50), (16, 1000, 3, False, 10), (16, 1000, 3, False, 50), (16, 1000, 3, True, 10), (16, 1000, 3, True, 50), (16, 1000, 1, False, 10), (16, 1000, 1, False, 50), (16, 1000, 1, True, 10), (16, 1000, 1, True, 50), (16, 1000, 5, False, 10), (16, 1000, 5, False, 50), (16, 1000, 5, True, 10), (16, 1000, 5, True, 50), (16, 10000, 3, False, 10), (16, 10000, 3, False, 50), (16, 10000, 3, True, 10), (16, 10000, 3, True, 50), (16, 10000, 1, False, 10), (16, 10000, 1, False, 50), (16, 10000, 1, True, 10), (16, 10000, 1, True, 50), (16, 10000, 5, False, 10), (16, 10000, 5, False, 50), (16, 10000, 5, True, 10), (16, 10000, 5, True, 50), (64, 100, 3, False, 10), (64, 100, 3, False, 50), (64, 100, 3, True, 10), (64, 100, 3, True, 50), (64, 100, 1, False, 10), (64, 100, 1, False, 50), (64, 100, 1, True, 10), (64, 100, 1, True, 50), (64, 100, 5, False, 10), (64, 100, 5, False, 50), (64, 100, 5, True, 10), (64, 100, 5, True, 50), (64, 1000, 3, False, 10), (64, 1000, 3, False, 50), (64, 1000, 3, True, 10), (64, 1000, 3, True, 50), (64, 1000, 1, False, 10), (64, 1000, 1, False, 50), (64, 1000, 1, True, 10), (64, 1000, 1, True, 50), (64, 1000, 5, False, 10), (64, 1000, 5, False, 50), (64, 1000, 5, True, 10), (64, 1000, 5, True, 50), (64, 10000, 3, False, 10), (64, 10000, 3, False, 50), (64, 10000, 3, True, 10), (64, 10000, 3, True, 50), (64, 10000, 1, False, 10), (64, 10000, 1, False, 50), (64, 10000, 1, True, 10), (64, 10000, 1, True, 50), (64, 10000, 5, False, 10), (64, 10000, 5, False, 50), (64, 10000, 5, True, 10), (64, 10000, 5, True, 50), (128, 100, 3, False, 10), (128, 100, 3, False, 50), (128, 100, 3, True, 10), (128, 100, 3, True, 50), (128, 100, 1, False, 10), (128, 100, 1, False, 50), (128, 100, 1, True, 10), (128, 100, 1, True, 50), (128, 100, 5, False, 10), (128, 100, 5, False, 50), (128, 100, 5, True, 10), (128, 100, 5, True, 50), (128, 1000, 3, False, 10), (128, 1000, 3, False, 50), (128, 1000, 3, True, 10), (128, 1000, 3, True, 50), (128, 1000, 1, False, 10), (128, 1000, 1, False, 50), (128, 1000, 1, True, 10), (128, 1000, 1, True, 50), (128, 1000, 5, False, 10), (128, 1000, 5, False, 50), (128, 1000, 5, True, 10), (128, 1000, 5, True, 50), (128, 10000, 3, False, 10), (128, 10000, 3, False, 50), (128, 10000, 3, True, 10), (128, 10000, 3, True, 50), (128, 10000, 1, False, 10), (128, 10000, 1, False, 50), (128, 10000, 1, True, 10), (128, 10000, 1, True, 50), (128, 10000, 5, False, 10), (128, 10000, 5, False, 50), (128, 10000, 5, True, 10), (128, 10000, 5, True, 50)]\n"
     ]
    }
   ],
   "source": [
    "# [batch_size, num_samples, trans_heads, dropout_trans, epochs]\n",
    "import itertools\n",
    "batch_size = [16, 64, 128]\n",
    "num_samples= [100, 1000, 10000]\n",
    "trans_heads= [3, 1, 5]\n",
    "dropout_trans = [False, True]\n",
    "epochs = [10, 50]\n",
    "\n",
    "combinations = [element for element in itertools.product(batch_size, num_samples, trans_heads, dropout_trans, epochs)]\n",
    "print(combinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing combination: (16, 100, 5, True, 10)\n",
      "loading classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 101/101 [00:00<00:00, 21980.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example datapoint: Data(x=[100, 1], y=8, pos=[100, 3], edge_index=[2, 124], edge_attr=[124, 3])\n",
      "loading classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 101/101 [00:00<00:00, 21734.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE: tensor([240, 180,   3])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing epoch 0\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.24: 100%|██████████| 434/434 [01:00<00:00,  7.17it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.2399193548387097, test accuracy: 0.24571428571428572\n",
      "computing epoch 1\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.27: 100%|██████████| 434/434 [00:53<00:00,  8.11it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.2744815668202765, test accuracy: 0.2582857142857143\n",
      "computing epoch 2\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.29: 100%|██████████| 434/434 [00:55<00:00,  7.86it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.28585829493087556, test accuracy: 0.2674285714285714\n",
      "computing epoch 3\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.3: 100%|██████████| 434/434 [00:56<00:00,  7.64it/s] \n",
      "100%|██████████| 14/14 [00:04<00:00,  3.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.2955069124423963, test accuracy: 0.3017142857142857\n",
      "computing epoch 4\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.31: 100%|██████████| 434/434 [00:57<00:00,  7.51it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.30630760368663595, test accuracy: 0.3097142857142857\n",
      "computing epoch 5\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.31: 100%|██████████| 434/434 [00:59<00:00,  7.27it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  3.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.30601958525345624, test accuracy: 0.29828571428571427\n",
      "computing epoch 6\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.31: 100%|██████████| 434/434 [01:00<00:00,  7.14it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.3109158986175115, test accuracy: 0.3062857142857143\n",
      "computing epoch 7\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.32: 100%|██████████| 434/434 [01:02<00:00,  6.95it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  2.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.31610023041474655, test accuracy: 0.3028571428571429\n",
      "computing epoch 8\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.32: 100%|██████████| 434/434 [01:04<00:00,  6.77it/s]\n",
      "100%|██████████| 14/14 [00:04<00:00,  2.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.31581221198156684, test accuracy: 0.3142857142857143\n",
      "computing epoch 9\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.32: 100%|██████████| 434/434 [01:05<00:00,  6.59it/s]\n",
      "100%|██████████| 14/14 [00:05<00:00,  2.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.3153801843317972, test accuracy: 0.296\n",
      "Testing combination: (64, 1000, 1, True, 10)\n",
      "loading classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 101/101 [00:00<00:00, 15073.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "example datapoint: Data(x=[1000, 1], y=8, pos=[1000, 3], edge_index=[2, 5851], edge_attr=[5851, 3])\n",
      "loading classes...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n",
      "Done!\n",
      "100%|██████████| 101/101 [00:00<00:00, 18412.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT SHAPE: tensor([240, 180,   3])\n",
      "computing epoch 0\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.25: 100%|██████████| 109/109 [04:32<00:00,  2.50s/it]\n",
      "100%|██████████| 14/14 [00:31<00:00,  2.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy: 0.24569954128440366, test accuracy: 0.272\n",
      "computing epoch 1\n",
      "234 iterations in total:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "precision so far is 0.27:  11%|█         | 12/109 [36:47<13:15:32, 492.09s/it]"
     ]
    }
   ],
   "source": [
    "# now we write the algo that runs experiments and keeps track of results, even after interruption\n",
    "# we need to manage a json file\n",
    "import json, os\n",
    "# steps are:\n",
    "# initialize the json\n",
    "# figure out which combinations aren't done yet\n",
    "# pick a random one, test\n",
    "# update the json\n",
    "import random\n",
    "import signal\n",
    "import sys\n",
    "\n",
    "def signal_handler(sig, frame):\n",
    "    print(\"Interrupt detected, saving results and exiting.\")\n",
    "    with open('results.json', 'w') as f:\n",
    "        json.dump(results, f)\n",
    "    sys.exit(0)\n",
    "\n",
    "signal.signal(signal.SIGINT, signal_handler)\n",
    "\n",
    "# Initialize the json\n",
    "if os.path.exists('results.json'):\n",
    "    with open('results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "else:\n",
    "    results = {}\n",
    "\n",
    "# Loop until all combinations are done\n",
    "while True:\n",
    "    # Figure out which combinations aren't done yet\n",
    "    pending_combinations = [c for c in combinations if str(c) not in results]\n",
    "\n",
    "    if not pending_combinations:\n",
    "        print(\"All combinations have been tested.\")\n",
    "        break\n",
    "\n",
    "    # Pick a random combination\n",
    "    random_combination = random.choice(pending_combinations)\n",
    "\n",
    "    print(f\"Testing combination: {random_combination}\")\n",
    "    try:\n",
    "        max_test_acc, test_acc, all_losses = single_run(*random_combination)\n",
    "        results[str(random_combination)] = {\n",
    "            \"max_test_acc\": max_test_acc,\n",
    "            \"test_acc\": test_acc,\n",
    "            # \"all_losses\": all_losses\n",
    "        }\n",
    "        with open('results.json', 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "    except Exception as e:\n",
    "        print(type(e))\n",
    "        # torch.cuda.OutOfMemoryError sometimes\n",
    "        print(f\"Error occurred while testing combination {random_combination}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # # what to do with the losses...\n",
    "# import numpy as np\n",
    "# example_accuracies = [\n",
    "#     np.array([0.256, 0.272, 0.26057142857142856, 0.2662857142857143, 0.272, 0.2674285714285714, 0.2925714285714286, 0.264]),\n",
    "#     0.5 * np.array([0.256, 0.272, 0.26057142857142856, 0.2662857142857143, 0.272, 0.2674285714285714, 0.2925714285714286, 0.264]),\n",
    "#     np.array([0.256, 0.272, 0.26057142857142856, 0.2662857142857143, 0.272, 0.2674285714285714, 0.2925714285714286, 0.264]) ** 2\n",
    "# ]\n",
    "\n",
    "# import matplotlib as mpl\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# for exacc in example_accuracies:\n",
    "#     ax.plot(range(len(exacc)), exacc)\n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the json\n",
    "import os, json\n",
    "if os.path.exists('results.json'):\n",
    "    with open('results.json', 'r') as f:\n",
    "        results = json.load(f)\n",
    "\n",
    "def calculate_average_accuracy(param_index, param_value):\n",
    "    relevant_combinations = [c for c in results.keys() if eval(c)[param_index] == param_value]\n",
    "    # total_accuracy = sum([results[c]['max_test_acc'] for c in relevant_combinations])\n",
    "    # return total_accuracy / len(relevant_combinations)\n",
    "    ret = [results[c]['max_test_acc'] for c in relevant_combinations]\n",
    "\n",
    "    return round(max(ret), 2), round(sum(ret) / len(ret), 2), len(ret)\n",
    "\n",
    "computed_combinations = [c for c in results.keys()]\n",
    "print(\"combinations computed:\", len(computed_combinations), \"/75\")\n",
    "\n",
    "parameters = [\"batch_size\", \"num_samples\", \"trans_heads\", \"dropout_trans\", \"epochs\"]\n",
    "values = [batch_size, num_samples, trans_heads, dropout_trans, epochs]\n",
    "\n",
    "for i, param in enumerate(parameters):\n",
    "    print(f\"(max, avg, n) accuracy for {param}:\")\n",
    "    for value in values[i]:\n",
    "        avg_accuracy = calculate_average_accuracy(i, value)\n",
    "        print(f\"  {value}: {avg_accuracy}\")\n",
    "    print()\n",
    "\n",
    "scores = []\n",
    "for r in results.keys():\n",
    "    scores.append((results[r]['max_test_acc'], r))\n",
    "scores.sort(reverse=True)\n",
    "[print(s) for s in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean():\n",
    "    # Initialize the json\n",
    "    results = {}\n",
    "    if os.path.exists('results.json'):\n",
    "        with open('results.json', 'r') as f:\n",
    "            results = json.load(f)\n",
    "    else:\n",
    "        results = {}\n",
    "    \n",
    "    for k, v in results.items():\n",
    "        if \"all_losses\" in v:\n",
    "            v.pop(\"all_losses\")\n",
    "    with open('results.json', 'w') as f:\n",
    "            json.dump(results, f, indent=4)\n",
    "\n",
    "# clean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57e03cdc9893d20d727156d0bac082b299e8387dff5042b3b647c6bfa1c939e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
