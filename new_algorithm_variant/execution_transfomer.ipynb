{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general imports\n",
    "import torch as th\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import DataLoader as PygDataLoader\n",
    "from torch.utils.data import SequentialSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch_geometric.data import DataLoader\n",
    "from dataloader import NCaltech101Best\n",
    "from model import GraphRes, GraphResModified, GraphResSimple, GraphTrans, GraphTransFinal\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params\n",
    "batch_size= 16\n",
    "lr=         10e-3 # decreases by 10 after each 20 epochs\n",
    "loss=       th.nn.CrossEntropyLoss\n",
    "batchsize=  16\n",
    "K=          10 # data subsampling\n",
    "nclasses=   100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_LAUNCH_BLOCKING=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device to use for training\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(\"using device:\", device)\n",
    "\n",
    "# Initialize dataset and data loader\n",
    "dataset = NCaltech101Best('./data/storage/', mode='train', num_samples=10000)\n",
    "# sampler = SequentialSampler(dataset)\n",
    "# loader = DataLoader(dataset, batch_size=16, sampler=sampler)\n",
    "loader = PygDataLoader(dataset, batch_size=32, shuffle=True)\n",
    "print(\"example datapoint:\", dataset.get(0))\n",
    "\n",
    "\n",
    "# Initialize model\n",
    "model_input_shape = th.tensor((240, 180) + (3, ), device=device)\n",
    "print(\"INPUT SHAPE:\", model_input_shape)\n",
    "model = GraphTransFinal('ncaltech101', model_input_shape, 101, dropout_trans=True, heads=1).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = CrossEntropyLoss().cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# for testing\n",
    "test_dataset = NCaltech101Best('./data/storage/', mode='test', num_samples=10000)\n",
    "test_loader = PygDataLoader(test_dataset, batch_size=32, shuffle=True)\n",
    "def run_model_test(model, loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "\n",
    "acc = []\n",
    "test_acc = []\n",
    "# Define training loop\n",
    "def train():\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct = 0\n",
    "    i = 0\n",
    "    print(\"234 iterations in total:\")\n",
    "    progbar = tqdm(loader)\n",
    "    for data in progbar:\n",
    "\n",
    "        # inference\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "\n",
    "        # weight updates\n",
    "        y = F.one_hot(data.y, num_classes=101).type(torch.cuda.FloatTensor)\n",
    "        loss = criterion(output, y)\n",
    "        losses.append(loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # precision logging\n",
    "        pred = output.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        i += 1\n",
    "        # if i % 50 == 0:\n",
    "        #     print(correct, i*16)\n",
    "        #     print(correct / (i*16))\n",
    "        # if i % 20 == 0 and i != 0:\n",
    "        #     print((i, round(correct / (i*16), 2)), end='->')\n",
    "        # if i % 100 == 0 and i != 0:   \n",
    "        #     print(\"\\n\", end='')\n",
    "        precision = round(correct / (i*32), 2)\n",
    "        progbar.set_description(\"precision so far is {}\".format(precision))\n",
    "    \n",
    "    # test, to check for overfitting\n",
    "    tacc = run_model_test(model, test_loader)\n",
    "    test_acc.append(tacc)\n",
    "    \n",
    "    acc.append(correct / (len(loader) * 32))\n",
    "    print(\"train accuracy: {}, test accuracy: {}\".format(acc[len(acc) - 1], tacc))\n",
    "    return losses\n",
    "\n",
    "# Run training loop for 10 epochs\n",
    "all_losses = []\n",
    "best_tacc = 0.0\n",
    "for epoch in range(100):\n",
    "    print(\"computing epoch\", epoch)\n",
    "    losses = train()\n",
    "    if test_acc[-1] > best_tacc:\n",
    "        torch.save(model, \"trained_graphtransfinal_best.model\")\n",
    "        best_tacc = test_acc[-1]\n",
    "    all_losses.append(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_losses[0][0].cpu().detach().numpy())\n",
    "def clean_losses(losses):\n",
    "    clean = []\n",
    "    for loss in losses:\n",
    "        ll = [float(l.cpu().detach().numpy()) for l in loss]\n",
    "        clean.append(ll)\n",
    "    return clean\n",
    "print(clean_losses(all_losses))\n",
    "print(test_acc)\n",
    "print(max(test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "dataset = NCaltech101Best('./data/storage/', mode='test')\n",
    "loader = PygDataLoader(dataset, batch_size=16, shuffle=True)\n",
    "def test(model, loader):\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    for data in tqdm(loader):\n",
    "        data = data.to(device)\n",
    "        with torch.no_grad():\n",
    "            out = model(data)\n",
    "            pred = out.max(dim=1)[1]\n",
    "            correct += pred.eq(data.y).sum().item()\n",
    "    return correct / len(loader.dataset)\n",
    "\n",
    "print(test(model,loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"trained_graphtrans.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_losses2 = [l.cpu().detach().numpy() for l in [**all_losses]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what to do with the losses...\n",
    "\n",
    "list_losses = []\n",
    "for losses in all_losses:\n",
    "    list_losses += losses\n",
    "\n",
    "list_losses2 = [l.cpu().detach().numpy() for l in list_losses]\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(range(len(list_losses2)), list_losses2)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_proj2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "57e03cdc9893d20d727156d0bac082b299e8387dff5042b3b647c6bfa1c939e3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
